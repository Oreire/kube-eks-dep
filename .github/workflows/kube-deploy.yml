name: Deploy and Clean EKS Infrastructure

on:
  push:
    branches: [main]
  # workflow_dispatch:
  #   inputs:
  #     auto_destroy:
  #       description: 'Destroy Infra? (true/false)'
  #       required: true
  #       default: 'false'
        
jobs:
  deploy-vpc:
    name: ğŸŒ Deploy VPC
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: KubeNet

    steps:
      - name: â¬‡ï¸ Checkout Code
        uses: actions/checkout@v3

      - name: ğŸ” Configure AWS
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }} 
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: eu-west-2

      - name: âš™ï¸ Setup Terraform
        uses: hashicorp/setup-terraform@v2

      - name: ğŸ§± Init VPC
        run: terraform init
      
      - name: ğŸ” Validate VPC
        run: terraform validate


      - name: ğŸ“‹ Plan VPC
        run: terraform plan -out=tfplan 

      - name: âœ… Apply VPC
        run: terraform apply -auto-approve tfplan

  deploy-eks:
    name: â˜¸ï¸ Deploy EKS
    needs: deploy-vpc
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: eks-cluster

    steps:
      - uses: actions/checkout@v3
      - uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: eu-west-2
      - uses: hashicorp/setup-terraform@v2
      - name: ğŸ§± Init eks-cluster
        run: terraform init

      - name: ğŸ” Validate eks-cluster
        run: terraform validate

      - name: ğŸ“‹ Plan eks-cluster
        run: terraform plan -out=tfplan 

      - name: âœ… Apply eks-cluster
        run: terraform apply -auto-approve tfplan

  # deploy-app:
  deploy-app:
    name: ğŸš€ Deploy Web Application
    needs: deploy-eks
    runs-on: ubuntu-latest
    defaults:
      run:
        working-directory: WEB
    env:
      AWS_REGION: eu-west-2
      CLUSTER_NAME: laredo-cluster  # Update if different
      KUBECTL_VERSION: v1.30.1


    steps:
      - name: ğŸ§¾ Checkout code
        uses: actions/checkout@v3

      - name: ğŸ” Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: ğŸ“¦ Install kubectl
        run: |
          KUBECTL_VERSION=v1.30.1  # or use: $(curl -s https://dl.k8s.io/release/stable.txt)
          echo "Installing kubectl version $KUBECTL_VERSION"
          curl -LO "https://dl.k8s.io/release/${KUBECTL_VERSION}/bin/linux/amd64/kubectl"
          chmod +x kubectl
          sudo mv kubectl /usr/local/bin/

      - name: ğŸ“¡ Update kubeconfig
        run: aws eks update-kubeconfig --region $AWS_REGION --name $CLUSTER_NAME
      
      - name: ğŸ” Verify kube context
        run: kubectl config current-context
    
      - name: âœ… Confirm nodes are ready
        run: kubectl get nodes --no-headers | grep -c ' Ready'
      
      - name: ğŸš€ Apply Kubernetes manifests
        run: |
          kubectl apply -f web-deploy.yaml
          kubectl apply -f web-svc.yaml

      - name: âœ… Verify Deployment
        run: kubectl get deployment ghs-web -n coweb-ns

      - name: âœ… Verify Service Exposure
        run: kubectl get svc ghs-service -n coweb-ns

      - name: ğŸ• Wait for LoadBalancer hostname
        run: |
          for i in {1..20}; do
            HOSTNAME=$(kubectl get svc ghs-service -n coweb-ns -o jsonpath="{.status.loadBalancer.ingress[0].hostname}")
            if [ -n "$HOSTNAME" ]; then
              echo "LoadBalancer endpoint is available at: http://$HOSTNAME"
              break
            fi
            echo "Waiting for LoadBalancer... ($i/20)"
            sleep 10
          done

      - name: ğŸŒ Print LoadBalancer endpoint
        run: |
          kubectl get svc ghs-service -n coweb-ns -o jsonpath="{.status.loadBalancer.ingress[0].hostname}"
          echo "LoadBalancer endpoint is available at: http://$(kubectl get svc ghs-service -n coweb-ns -o jsonpath="{.status.loadBalancer.ingress[0].hostname}")"

      - name: âœ… Verify rollout
        run: kubectl rollout status deployment/ghs-web -n coweb-ns

  teardown-infra:
    # if: github.event_name == 'workflow_dispatch' && github.event.inputs.auto_destroy == 'true'
    name: ğŸ§¹ Teardown Infra (auto after delay)
    needs: deploy-app
    runs-on: ubuntu-latest
    steps:
      - name: â²ï¸ Wait for 2 minutes
        run: sleep 120

      - name: â¬‡ï¸ Checkout Code
        uses: actions/checkout@v3

      - name: ğŸ” Configure AWS
        uses: aws-actions/configure-aws-credentials@v2
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: eu-west-2

      - name: âš™ï¸ Setup Terraform
        uses: hashicorp/setup-terraform@v2

      - name: ğŸ§¹ Destroy EKS
        run: |
           cd eks-cluster
           terraform init
           terraform destroy -auto-approve

      - name: ğŸŒ Destroy VPC
        run: |
          cd ../KubeNet
          terraform init
          terraform destroy -auto-approve

